{
  "name": "Recommendation AI Agent",
  "year": 2023,
  "url": "https://arxiv.org/html/2308.16505v3",
  "title": "Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations",
  "sections": {
    "S1": "1 Introduction",
    "S2": "2 Related Work",
    "S3": "3 Methodologies",
    "S4": "4 Experiments",
    "S5": "5 Conclusion"
  },
  "citations": [
    {
      "section_id": "S1",
      "cite_enum": "2",
      "cite_id": "2",
      "sentence": "Large language models (LLMs), such as GPT-3(Brown et al2020)and PaLM(Chowdhery et al2022), have made significant strides in recent years, demonstrating remarkable capabilities in artificial general intelligence and revolutionizing the field of natural language processing"
    },
    {
      "section_id": "S1",
      "cite_enum": "6",
      "cite_id": "6",
      "sentence": "Large language models (LLMs), such as GPT-3(Brown et al2020)and PaLM(Chowdhery et al2022), have made significant strides in recent years, demonstrating remarkable capabilities in artificial general intelligence and revolutionizing the field of natural language processing"
    },
    {
      "section_id": "S1",
      "cite_enum": "30",
      "cite_id": "30",
      "sentence": "com/Significant-Gravitas/Auto-GPT, HuggingGPT(Shen et al2023), and Visual ChatGPT(Wu et al2023)"
    },
    {
      "section_id": "S1",
      "cite_enum": "45",
      "cite_id": "45",
      "sentence": "com/Significant-Gravitas/Auto-GPT, HuggingGPT(Shen et al2023), and Visual ChatGPT(Wu et al2023)"
    },
    {
      "section_id": "S1",
      "cite_enum": "35",
      "cite_id": "35",
      "sentence": "Through fine-tuning the LlaMA 2(Touvron et al2023b)model with this dataset, we have created RecLlama"
    },
    {
      "section_id": "S2",
      "cite_enum": "9",
      "cite_id": "9",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "56",
      "cite_id": "56",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "55",
      "cite_id": "55",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "47",
      "cite_id": "47",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "15",
      "cite_id": "15",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "43",
      "cite_id": "43",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "36",
      "cite_id": "36",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "21",
      "cite_id": "21",
      "sentence": "Key research challenges in this area include developing strategies for selecting queried attributes(Mirzadeh, Ricci, and Bansal2005; Zhang et al2018)and addressing the exploration-exploitation trade-off(Christakopoulou, Radlinski, and Hofmann2016; Xie et al2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "51",
      "cite_id": "51",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "7",
      "cite_id": "7",
      "sentence": "Key research challenges in this area include developing strategies for selecting queried attributes(Mirzadeh, Ricci, and Bansal2005; Zhang et al2018)and addressing the exploration-exploitation trade-off(Christakopoulou, Radlinski, and Hofmann2016; Xie et al2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "46",
      "cite_id": "46",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "15",
      "cite_id": "15",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "25",
      "cite_id": "25",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "3",
      "cite_id": "3",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "40",
      "cite_id": "40",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "43",
      "cite_id": "43",
      "sentence": "Existing researches in conversational recommender systems (CRS) can be primarily categorized into two main areas(Gao et al2021): attribute-based question-answering(Zou and Kanoulas2019; Zou, Chen, and Kanoulas2020; Xu et al2021)and open-ended conversation(Li et al2018; Wang et al2022b,2021)"
    },
    {
      "section_id": "S2",
      "cite_enum": "2",
      "cite_id": "2",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "18",
      "cite_id": "18",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "28",
      "cite_id": "28",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "24",
      "cite_id": "24",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "34",
      "cite_id": "34",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "23",
      "cite_id": "23",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "44",
      "cite_id": "44",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "42",
      "cite_id": "42",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "50",
      "cite_id": "50",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "48",
      "cite_id": "48",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "39",
      "cite_id": "39",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "17",
      "cite_id": "17",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "8",
      "cite_id": "8",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "13",
      "cite_id": "13",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "37",
      "cite_id": "37",
      "sentence": "The scaling-up of parameters and data has led to significant advancements in the capabilities of LLMs, including in-context learning(Brown et al2020; Liu et al2021; Rubin, Herzig, and Berant2021), instruction following(Ouyang et al2022; Touvron et al2023a; OpenAI2023), planning and reasoning(Wei et al2022; Wang et al2022a; Yao et al2022; Yang et al2023; Wang et al2023b)"
    },
    {
      "section_id": "S2",
      "cite_enum": "38",
      "cite_id": "38",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "52",
      "cite_id": "52",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "41",
      "cite_id": "41",
      "sentence": "For example,(Wang et al2023c; Zhong et al2023; Liu et al2023b)have equipped LLMs with an external memory, empowering LLMs with growth potential Regarding the planning, CoT(Wei et al2022; Kojima et al2022)and ReAct(Yao et al2022)propose to enhance planning by step-wise reasoning; ToT(Yao et al2023)and GoT(Besta et al2023)introduce multi-path reasoning to ensure consistency and correctness; Self-Refine(Madaan et al2023)and Reflexion(Shinn et al2023)lead the LLMs to reflect on errors, with the ultimate goal of improving their subsequent problem-solving success rates"
    },
    {
      "section_id": "S2",
      "cite_enum": "54",
      "cite_id": "54",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "19",
      "cite_id": "19",
      "sentence": "For example,(Wang et al2023c; Zhong et al2023; Liu et al2023b)have equipped LLMs with an external memory, empowering LLMs with growth potential Regarding the planning, CoT(Wei et al2022; Kojima et al2022)and ReAct(Yao et al2022)propose to enhance planning by step-wise reasoning; ToT(Yao et al2023)and GoT(Besta et al2023)introduce multi-path reasoning to ensure consistency and correctness; Self-Refine(Madaan et al2023)and Reflexion(Shinn et al2023)lead the LLMs to reflect on errors, with the ultimate goal of improving their subsequent problem-solving success rates"
    },
    {
      "section_id": "S2",
      "cite_enum": "44",
      "cite_id": "44",
      "sentence": "For example,(Wang et al2023c; Zhong et al2023; Liu et al2023b)have equipped LLMs with an external memory, empowering LLMs with growth potential Regarding the planning, CoT(Wei et al2022; Kojima et al2022)and ReAct(Yao et al2022)propose to enhance planning by step-wise reasoning; ToT(Yao et al2023)and GoT(Besta et al2023)introduce multi-path reasoning to ensure consistency and correctness; Self-Refine(Madaan et al2023)and Reflexion(Shinn et al2023)lead the LLMs to reflect on errors, with the ultimate goal of improving their subsequent problem-solving success rates"
    },
    {
      "section_id": "S2",
      "cite_enum": "14",
      "cite_id": "14",
      "sentence": "For example,(Wang et al2023c; Zhong et al2023; Liu et al2023b)have equipped LLMs with an external memory, empowering LLMs with growth potential Regarding the planning, CoT(Wei et al2022; Kojima et al2022)and ReAct(Yao et al2022)propose to enhance planning by step-wise reasoning; ToT(Yao et al2023)and GoT(Besta et al2023)introduce multi-path reasoning to ensure consistency and correctness; Self-Refine(Madaan et al2023)and Reflexion(Shinn et al2023)lead the LLMs to reflect on errors, with the ultimate goal of improving their subsequent problem-solving success rates"
    },
    {
      "section_id": "S2",
      "cite_enum": "50",
      "cite_id": "50",
      "sentence": "For example,(Wang et al2023c; Zhong et al2023; Liu et al2023b)have equipped LLMs with an external memory, empowering LLMs with growth potential Regarding the planning, CoT(Wei et al2022; Kojima et al2022)and ReAct(Yao et al2022)propose to enhance planning by step-wise reasoning; ToT(Yao et al2023)and GoT(Besta et al2023)introduce multi-path reasoning to ensure consistency and correctness; Self-Refine(Madaan et al2023)and Reflexion(Shinn et al2023)lead the LLMs to reflect on errors, with the ultimate goal of improving their subsequent problem-solving success rates"
    },
    {
      "section_id": "S2",
      "cite_enum": "49",
      "cite_id": "49",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "1",
      "cite_id": "1",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "20",
      "cite_id": "20",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "31",
      "cite_id": "31",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "26",
      "cite_id": "26",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "22",
      "cite_id": "22",
      "sentence": "To possess domain-specific skills, some works(Qin et al2023a)study guiding LLMs to use external tools, such as a web search engine(Nakano et al2021; Shuster et al2022), mathematical tools(Schick et al2023; Thoppilan et al2022), code interpreters(Gao et al2023a; Chen et al2022)and visual models(Wu et al2023; Shen et al2023)"
    },
    {
      "section_id": "S2",
      "cite_enum": "32",
      "cite_id": "32",
      "sentence": "For example,(Wang et al2023c; Zhong et al2023; Liu et al2023b)have equipped LLMs with an external memory, empowering LLMs with growth potential Regarding the planning, CoT(Wei et al2022; Kojima et al2022)and ReAct(Yao et al2022)propose to enhance planning by step-wise reasoning; ToT(Yao et al2023)and GoT(Besta et al2023)introduce multi-path reasoning to ensure consistency and correctness; Self-Refine(Madaan et al2023)and Reflexion(Shinn et al2023)lead the LLMs to reflect on errors, with the ultimate goal of improving their subsequent problem-solving success rates"
    },
    {
      "section_id": "S2",
      "cite_enum": "29",
      "cite_id": "29",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "33",
      "cite_id": "33",
      "sentence": "For example,(Wang et al2023c; Zhong et al2023; Liu et al2023b)have equipped LLMs with an external memory, empowering LLMs with growth potential Regarding the planning, CoT(Wei et al2022; Kojima et al2022)and ReAct(Yao et al2022)propose to enhance planning by step-wise reasoning; ToT(Yao et al2023)and GoT(Besta et al2023)introduce multi-path reasoning to ensure consistency and correctness; Self-Refine(Madaan et al2023)and Reflexion(Shinn et al2023)lead the LLMs to reflect on errors, with the ultimate goal of improving their subsequent problem-solving success rates"
    },
    {
      "section_id": "S2",
      "cite_enum": "10",
      "cite_id": "10",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "4",
      "cite_id": "4",
      "sentence": "For example,(Wang et al2023c; Zhong et al2023; Liu et al2023b)have equipped LLMs with an external memory, empowering LLMs with growth potential Regarding the planning, CoT(Wei et al2022; Kojima et al2022)and ReAct(Yao et al2022)propose to enhance planning by step-wise reasoning; ToT(Yao et al2023)and GoT(Besta et al2023)introduce multi-path reasoning to ensure consistency and correctness; Self-Refine(Madaan et al2023)and Reflexion(Shinn et al2023)lead the LLMs to reflect on errors, with the ultimate goal of improving their subsequent problem-solving success rates"
    },
    {
      "section_id": "S2",
      "cite_enum": "45",
      "cite_id": "45",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S2",
      "cite_enum": "30",
      "cite_id": "30",
      "sentence": "As models show emergent intelligence, researchers have started exploring the potential to leverage LLMs as autonomous agents(Wang et al2023a; Zhao, Jin, and Cheng2023), augmented with memory modules, planning ability, and tool-using capabilities"
    },
    {
      "section_id": "S3",
      "cite_enum": "50",
      "cite_id": "50",
      "sentence": "Typically, the tool augmentation is implemented via ReAct(Yao et al2022), where LLMs generate reasoning traces, actions, and observations in an interleaved manner"
    },
    {
      "section_id": "S3",
      "cite_enum": "20",
      "cite_id": "20",
      "sentence": "Inspired by Self-Instruct(Madaan et al2023), we use LLM to generate demonstrations of tool-using plans in the form of(x,ùíë)ùë•ùíë(x,\\boldsymbol{p})( italic_x , bold_italic_p )"
    },
    {
      "section_id": "S3",
      "cite_enum": "20",
      "cite_id": "20",
      "sentence": "Despite LLM‚Äôs strong intelligence, it still exhibits occasional errors in reasoning and tool utilization(Madaan et al2023; Shinn et al2023)"
    },
    {
      "section_id": "S3",
      "cite_enum": "31",
      "cite_id": "31",
      "sentence": "Despite LLM‚Äôs strong intelligence, it still exhibits occasional errors in reasoning and tool utilization(Madaan et al2023; Shinn et al2023)"
    },
    {
      "section_id": "S3",
      "cite_enum": "31",
      "cite_id": "31",
      "sentence": "To reduce the occurrence of such errors, some studies have employed self-reflection(Shinn et al2023)mechanisms to enable LLM to have some error-correcting capabilities during decision-making"
    },
    {
      "section_id": "S4",
      "cite_enum": "15",
      "cite_id": "15",
      "sentence": "Following the settings of traditional conversational recommender systems on ReDial(Li et al2018), we also adopt the one-turn recommendation strategy"
    },
    {
      "section_id": "S4",
      "cite_enum": "35",
      "cite_id": "35",
      "sentence": "LlaMA-2-7B-chat,LlaMA-2-13B-chat(Touvron et al2023b): The second version of the LlaMA model released by Meta"
    },
    {
      "section_id": "S4",
      "cite_enum": "5",
      "cite_id": "5",
      "sentence": "5-13B(Chiang et al2023): Open-source models fine-tuned with user-shared data from the ShareGPT888https://sharegpt"
    },
    {
      "section_id": "S4",
      "cite_enum": "11",
      "cite_id": "11",
      "sentence": "Chat-Rec(Gao et al2023b): A recently proposed conversational recommendation agent utilizes a text-embedding tool (OpenAI text-embedding-ada-002) to retrieve candidates"
    },
    {
      "section_id": "S4",
      "cite_enum": "23",
      "cite_id": "23",
      "sentence": "5,GPT-4(OpenAI2023): We access these LLMs from OpenAI by API service"
    },
    {
      "section_id": "S4",
      "cite_enum": "53",
      "cite_id": "53",
      "sentence": "For the LlaMA and Vicuna models, we employ the FastChat(Zheng et al2023)package to establish local APIs, ensuring their usage is consistent with GPT-3"
    },
    {
      "section_id": "S4",
      "cite_enum": "16",
      "cite_id": "16",
      "sentence": "Regarding tools, we use SQL as information query tool, SQL and ItemCF(Linden, Smith, and York2003)as hard condition and soft condition item retrieval tools, respectively, and SASRec(Kang and McAuley2018)without position embedding as the ranking tool"
    },
    {
      "section_id": "S4",
      "cite_enum": "12",
      "cite_id": "12",
      "sentence": "Regarding tools, we use SQL as information query tool, SQL and ItemCF(Linden, Smith, and York2003)as hard condition and soft condition item retrieval tools, respectively, and SASRec(Kang and McAuley2018)without position embedding as the ranking tool"
    },
    {
      "section_id": "S4",
      "cite_enum": "27",
      "cite_id": "27",
      "sentence": "ToolLlaMA2-7B(Qin et al2023b)is another fine-tuned model designed to interact with external APIs in response to human instructions"
    }
  ],
  "preview": "<div class=\"ltx_para\" id=\"S1.p1\">\n<p class=\"ltx_p\" id=\"S1.p1.1\">Recommender systems (RSs) have become an essential component of the digital landscape, playing a significant role in helping users navigate the vast array of choices available across various domains such as e-commerce and entertainment. By analyzing user preferences, historical data, and contextual information, these systems can deliver personalized recommendations that cater to individual tastes. Over the years, recommender systems have evolved from simple collaborative filtering algorithms to more advanced hybrid approaches that integrate deep learning techniques. However, as users increasingly rely on conversational interfaces for discovering and exploring products, there is a growing need to develop more sophisticated and interactive recommendation systems that can understand and respond effectively to diverse user inquiries and intents in an conversational manner.</p>\n</div><div class=\"ltx_para\" id=\"S1.p2\">\n<p class=\"ltx_p\" id=\"S1.p2.1\">Large language models (LLMs), such as GPT-3¬† and PaLM¬†, have made significant strides in recent years, demonstrating remarkable capabilities in artificial general intelligence and revolutionizing the field of natural language processing. A variety of practical tasks can be accomplished in the manner of users conversing with AI agents such as ChatGPT¬†<span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span><a class=\"ltx_ref ltx_url\" href=\"https://chat.openai.com/\" title=\"\">https://chat.openai.com/</a></span></span></span> and Claude¬†<span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span><a class=\"ltx_ref ltx_url\" href=\"https://claude.ai/\" title=\"\">https://claude.ai/</a></span></span></span>.\nWith their ability to understand context, generate human-like text, and perform complex reasoning tasks, LLMs can facilitate more engaging and intuitive interactions between users and RSs, thus offering promising prospects for the next generation of RSs. By integrating LLMs into RSs, it becomes possible to provide a more natural and seamless user experience that goes beyond traditional recommendation techniques, fostering a more timely understanding of user preferences and delivering more comprehensive and persuasive suggestions.</p>\n</div><div class=\"ltx_para\" id=\"S1.p3\">\n<p class=\"ltx_p\" id=\"S1.p3.1\">Despite their potential, leveraging LLMs for recommender systems is not without its challenges and limitations. Firstly, while LLMs are pretrained on vast amounts of textual data from the internet, covering various domains and demonstrating impressive general world knowledge, they may fail to capture fine-grained, domain-specific behavior patterns, especially in domains with massive training data. Secondly, LLMs may struggle to understand a domain well if the domain data is private and less openly accessible on the internet. Thirdly, LLMs lack knowledge of new items released after the collection of pretraining data, and fine-tuning with up-to-date data can be prohibitively expensive. In contrast, in-domain models can naturally address these challenges. A common paradigm to overcome these limitations is to combine LLMs with in-domain models, thereby filling the gaps and producing more powerful intelligence. Notable examples include AutoGPT¬†<span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\"><sup class=\"ltx_note_mark\">4</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">4</sup><span class=\"ltx_tag ltx_tag_note\">4</span><a class=\"ltx_ref ltx_url\" href=\"https://github.com/Significant-Gravitas/Auto-GPT\" title=\"\">https://github.com/Significant-Gravitas/Auto-GPT</a></span></span></span>, HuggingGPT, and Visual ChatGPT. The core idea is to utilize LLMs as the ‚Äúbrains‚Äù and in-domain models as ‚Äútools‚Äù that extend LLMs‚Äô capabilities when handling domain-specific tasks.</p>\n</div><div class=\"ltx_para\" id=\"S1.p4\">\n<p class=\"ltx_p\" id=\"S1.p4.1\">In this paper, we connect LLMs with traditional recommendation models for interactive recommender systems. We propose InteRecAgent (<span class=\"ltx_text ltx_font_bold\" id=\"S1.p4.1.1\">Inte</span>ractive <span class=\"ltx_text ltx_font_bold\" id=\"S1.p4.1.2\">Rec</span>ommender <span class=\"ltx_text ltx_font_bold\" id=\"S1.p4.1.3\">Agent</span>), a framework explicitly designed to cater to the specific requirements and nuances of recommender systems, thereby establishing a more effective connection between the LLM‚Äôs general capabilities and the specialized needs of the recommendation domain.\nThis framework consists of three distinct sets of tools, including querying, retrieval, and ranking, which are designed to cater to the diverse needs of users‚Äô daily inquiries.\nGiven the typically large number of item candidates, storing item names in the tools‚Äô input and output as observations with prompts is impractical. Therefore, we introduce a ‚Äúshared candidate bus‚Äù to store intermediate states and facilitate communication between tools.\nTo enhance the capabilities of dealing with long conversations and even lifelong conversations, we introduce a ‚Äúlong-term and short-term user profile‚Äù module to track the preferences and history of the user, leveraged as the input of the ranking tool to improve personalization. The ‚Äúshared candidate bus‚Äù along with the ‚Äúlong-term and short-term user profile‚Äù constitute the advanced memory mechanisms within the InteRecAgent framework.</p>\n</div><div class=\"ltx_para\" id=\"S1.p5\">\n<p class=\"ltx_p\" id=\"S1.p5.1\">Regarding task planning, we employ a ‚Äúplan-first execution‚Äù strategy as opposed to a <span class=\"ltx_text ltx_font_slanted\" id=\"S1.p5.1.1\">step-by-step</span> approach. This strategy not only lowers the inference costs of LLMs but can also be seamlessly integrated with the dynamic demonstration strategy to enhance the quality of plan generation. Specifically, InteRecAgent generates all the steps of tool-calling at once and strictly follows the execution plan to accomplish the task. During the conversation, InteRecAgent parses the user‚Äôs intent and retrieves a few demonstrations that are most similar to the current intent. These dynamically retrieved demonstrations help LLMs formulate a correct task execution plan.\nIn addition, we implement a reflection strategy, wherein another LLM acts as a critic to evaluate the quality of the results and identify any errors during the task execution. If the results are unsatisfactory or errors are detected, InteRecAgent reverts to the initial state and repeats the plan-then-tool-execution process.\n</p>\n</div><div class=\"ltx_para\" id=\"S1.p6\">\n<p class=\"ltx_p\" id=\"S1.p6.1\">Employing GPT-4 as the LLM within InteRecAgent has yielded impressive results in our experiments. This naturally leads to the attractive question: is it possible to harness a smaller language model to act as the brain? To explore this, we have developed an imitation dataset featuring tool plan generations derived from interactions between InteRecAgent and a user simulator, both powered by GPT-4. Through fine-tuning the LlaMA 2¬† model with this dataset, we have created RecLlama. Remarkably, RecLlama surpasses several larger models in its effectiveness as the core of a recommender agent.\nOur main contributions are summarized as follows:</p>\n<ul class=\"ltx_itemize\" id=\"S1.I1\">\n<li class=\"ltx_item\" id=\"S1.I1.i1\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">‚Ä¢</span>\n<div class=\"ltx_para\" id=\"S1.I1.i1.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i1.p1.1\">We propose InteRecAgent, a compact LLM-based agent framework that democratizes interactive recommender systems by connecting LLMs with three distinct sets of traditional recommendation tools.</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i2\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">‚Ä¢</span>\n<div class=\"ltx_para\" id=\"S1.I1.i2.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i2.p1.1\">In response to the challenges posed by the application of LLM-based agents in recommendation systems, we introduce a suite of advanced modules, including shared candidate bus, long-term and short-term user profile, dynamic demonstration-augmented plan-first strategy, and a reflection strategy.</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i3\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">‚Ä¢</span>\n<div class=\"ltx_para\" id=\"S1.I1.i3.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i3.p1.1\">To enable small language models to serve as the brain for recommender agents, we create an imitation dataset derived from GPT-4. Leveraging this dataset, we have successfully fine-tuned a 7-billion-parameter model, which we refer to as RecLlama.</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i4\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">‚Ä¢</span>\n<div class=\"ltx_para\" id=\"S1.I1.i4.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i4.p1.1\">Experimental results from three public datasets demonstrate the effectiveness of InteRecAgent, with particularly significant advantages in domains that are less covered by world knowledge.</p>\n</div>\n</li>\n</ul>\n</div><div class=\"ltx_para\" id=\"S1.I1.i1.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i1.p1.1\">We propose InteRecAgent, a compact LLM-based agent framework that democratizes interactive recommender systems by connecting LLMs with three distinct sets of traditional recommendation tools.</p>\n</div><div class=\"ltx_para\" id=\"S1.I1.i2.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i2.p1.1\">In response to the challenges posed by the application of LLM-based agents in recommendation systems, we introduce a suite of advanced modules, including shared candidate bus, long-term and short-term user profile, dynamic demonstration-augmented plan-first strategy, and a reflection strategy.</p>\n</div><div class=\"ltx_para\" id=\"S1.I1.i3.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i3.p1.1\">To enable small language models to serve as the brain for recommender agents, we create an imitation dataset derived from GPT-4. Leveraging this dataset, we have successfully fine-tuned a 7-billion-parameter model, which we refer to as RecLlama.</p>\n</div><div class=\"ltx_para\" id=\"S1.I1.i4.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i4.p1.1\">Experimental results from three public datasets demonstrate the effectiveness of InteRecAgent, with particularly significant advantages in domains that are less covered by world knowledge.</p>\n</div>",
  "references": {
    "1": {
      "enum": "1",
      "authors": "Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler",
      "title": "Graph of thoughts: Solving elaborate problems with large language models",
      "publication": "arXiv preprint arXiv:2308.09687",
      "year": 2023,
      "summary": "We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information (\"LLM thoughts\") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over ToT, while simultaneously reducing costs by >31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.",
      "standard_url": "http://arxiv.org/abs/2308.09687v4",
      "id": "2023-graph_of_thoughts:_solving_elaborate_problems_with_large_language_models"
    },
    "2": {
      "enum": "2",
      "authors": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei",
      "title": "Language models are few-shot learners",
      "publication": "Advances in neural information processing systems, 33: 1877‚Äì1901",
      "year": 2020,
      "summary": "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.",
      "standard_url": "http://arxiv.org/abs/2005.14165v4",
      "id": "2020-language_models_are_few-shot_learners"
    },
    "3": {
      "enum": "3",
      "authors": "Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding, Yukuo Cen, Hongxia Yang, Jie Tang",
      "title": "Towards knowledge-based recommender dialog system",
      "publication": "arXiv preprint arXiv:1908.05391",
      "year": 2019,
      "summary": "In this paper, we propose a novel end-to-end framework called KBRD, which stands for Knowledge-Based Recommender Dialog System. It integrates the recommender system and the dialog generation system. The dialog system can enhance the performance of the recommendation system by introducing knowledge-grounded information about users' preferences, and the recommender system can improve that of the dialog generation system by providing recommendation-aware vocabulary bias. Experimental results demonstrate that our proposed model has significant advantages over the baselines in both the evaluation of dialog generation and recommendation. A series of analyses show that the two systems can bring mutual benefits to each other, and the introduced knowledge contributes to both their performances.",
      "standard_url": "http://arxiv.org/abs/1908.05391v2",
      "id": "2019-towards_knowledge-based_recommender_dialog_system"
    },
    "4": {
      "enum": "4",
      "authors": "Wenhu Chen, Xueguang Ma, Xinyi Wang, William W. Cohen",
      "title": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
      "publication": "arXiv preprint arXiv:2211.12588",
      "year": 2022,
      "summary": "Recently, there has been significant progress in teaching language models to perform step-by-step reasoning to solve complex numerical reasoning tasks. Chain-of-thoughts prompting (CoT) is by far the state-of-art method for these tasks. CoT uses language models to perform both reasoning and computation in the multi-step `thought' process. To disentangle computation from reasoning, we propose `Program of Thoughts' (PoT), which uses language models (mainly Codex) to express the reasoning process as a program. The computation is relegated to an external computer, which executes the generated programs to derive the answer. We evaluate PoT on five math word problem datasets (GSM, AQuA, SVAMP, TabMWP, MultiArith) and three financial-QA datasets (FinQA, ConvFinQA, TATQA) for both few-shot and zero-shot setups. Under both few-shot and zero-shot settings, PoT can show an average performance gain over CoT by around 12\\% across all the evaluated datasets. By combining PoT with self-consistency decoding, we can achieve SoTA performance on all math problem datasets and near-SoTA performance on financial datasets. All of our data and code are released in Github https://github.com/wenhuchen/Program-of-Thoughts",
      "standard_url": "http://arxiv.org/abs/2211.12588v4",
      "id": "2022-program_of_thoughts_prompting:_disentangling_computation_from_reasoning_for_numerical_reasoning_tasks"
    },
    "5": {
      "enum": "5",
      "authors": "Chiang, W.-L.; Li, Z.; Lin, Z.; Sheng, Y.; Wu, Z.; Zhang, H.; Zheng, L.; Zhuang, S.; Zhuang, Y.; Gonzalez, J. E.; Stoica, I.; and Xing, E. P. 2023",
      "title": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality",
      "publication": null,
      "year": null,
      "summary": null,
      "standard_url": null,
      "id": "None-vicuna:_an_open-source_chatbot_impressing_gpt-4_with_90%*_chatgpt_quality"
    },
    "6": {
      "enum": "6",
      "authors": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, Noah Fiedel",
      "title": "Palm: Scaling language modeling with pathways",
      "publication": "arXiv preprint arXiv:2204.02311",
      "year": 2022,
      "summary": "Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.",
      "standard_url": "http://arxiv.org/abs/2204.02311v5",
      "id": "2022-palm:_scaling_language_modeling_with_pathways"
    },
    "7": {
      "enum": "7",
      "authors": "Peixin Qin, Chen Huang, Yang Deng, Wenqiang Lei, Tat-Seng Chua",
      "title": "Towards conversational recommender systems",
      "publication": "In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 815‚Äì824",
      "year": 2024,
      "summary": "With the aid of large language models, current conversational recommender system (CRS) has gaining strong abilities to persuade users to accept recommended items. While these CRSs are highly persuasive, they can mislead users by incorporating incredible information in their explanations, ultimately damaging the long-term trust between users and the CRS. To address this, we propose a simple yet effective method, called PC-CRS, to enhance the credibility of CRS's explanations during persuasion. It guides the explanation generation through our proposed credibility-aware persuasive strategies and then gradually refines explanations via post-hoc self-reflection. Experimental results demonstrate the efficacy of PC-CRS in promoting persuasive and credible explanations. Further analysis reveals the reason behind current methods producing incredible explanations and the potential of credible explanations to improve recommendation accuracy.",
      "standard_url": "http://arxiv.org/abs/2409.14399v2",
      "id": "2024-towards_conversational_recommender_systems"
    },
    "8": {
      "enum": "8",
      "authors": "Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao Zhang, Jun Xu",
      "title": "Uncovering ChatGPT‚Äôs Capabilities in Recommender Systems",
      "publication": "arXiv preprint arXiv:2305.02182",
      "year": 2023,
      "summary": "The debut of ChatGPT has recently attracted the attention of the natural language processing (NLP) community and beyond. Existing studies have demonstrated that ChatGPT shows significant improvement in a range of downstream NLP tasks, but the capabilities and limitations of ChatGPT in terms of recommendations remain unclear. In this study, we aim to conduct an empirical analysis of ChatGPT's recommendation ability from an Information Retrieval (IR) perspective, including point-wise, pair-wise, and list-wise ranking. To achieve this goal, we re-formulate the above three recommendation policies into a domain-specific prompt format. Through extensive experiments on four datasets from different domains, we demonstrate that ChatGPT outperforms other large language models across all three ranking policies. Based on the analysis of unit cost improvements, we identify that ChatGPT with list-wise ranking achieves the best trade-off between cost and performance compared to point-wise and pair-wise ranking. Moreover, ChatGPT shows the potential for mitigating the cold start problem and explainable recommendation. To facilitate further explorations in this area, the full code and detailed original results are open-sourced at https://github.com/rainym00d/LLM4RS.",
      "standard_url": "http://arxiv.org/abs/2305.02182v3",
      "id": "2023-uncovering_chatgpt‚Äôs_capabilities_in_recommender_systems"
    },
    "9": {
      "enum": "9",
      "authors": "Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten de Rijke, Tat-Seng Chua",
      "title": "Advances and challenges in conversational recommender systems: A survey",
      "publication": "AI Open, 2: 100‚Äì126",
      "year": 2021,
      "summary": "Recommender systems exploit interaction history to estimate user preference, having been heavily used in a wide range of industry applications. However, static recommendation models are difficult to answer two important questions well due to inherent shortcomings: (a) What exactly does a user like? (b) Why does a user like an item? The shortcomings are due to the way that static models learn user preference, i.e., without explicit instructions and active feedback from users. The recent rise of conversational recommender systems (CRSs) changes this situation fundamentally. In a CRS, users and the system can dynamically communicate through natural language interactions, which provide unprecedented opportunities to explicitly obtain the exact preference of users.\n  Considerable efforts, spread across disparate settings and applications, have been put into developing CRSs. Existing models, technologies, and evaluation methods for CRSs are far from mature. In this paper, we provide a systematic review of the techniques used in current CRSs. We summarize the key challenges of developing CRSs in five directions: (1) Question-based user preference elicitation. (2) Multi-turn conversational recommendation strategies. (3) Dialogue understanding and generation. (4) Exploitation-exploration trade-offs. (5) Evaluation and user simulation. These research directions involve multiple research fields like information retrieval (IR), natural language processing (NLP), and human-computer interaction (HCI). Based on these research directions, we discuss some future challenges and opportunities. We provide a road map for researchers from multiple communities to get started in this area. We hope this survey can help to identify and address challenges in CRSs and inspire future research.",
      "standard_url": "http://arxiv.org/abs/2101.09459v7",
      "id": "2021-advances_and_challenges_in_conversational_recommender_systems:_a_survey"
    },
    "10": {
      "enum": "10",
      "authors": "Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig",
      "title": "Pal: Program-aided language models",
      "publication": "In International Conference on Machine Learning, 10764‚Äì10799. PMLR",
      "year": 2022,
      "summary": "Large language models (LLMs) have recently demonstrated an impressive ability to perform arithmetic and symbolic reasoning tasks, when provided with a few examples at test time (\"few-shot prompting\"). Much of this success can be attributed to prompting methods such as \"chain-of-thought'', which employ LLMs for both understanding the problem description by decomposing it into steps, as well as solving each step of the problem. While LLMs seem to be adept at this sort of step-by-step decomposition, LLMs often make logical and arithmetic mistakes in the solution part, even when the problem is decomposed correctly. In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter. With PAL, decomposing the natural language problem into runnable steps remains the only learning task for the LLM, while solving is delegated to the interpreter. We demonstrate this synergy between a neural LLM and a symbolic interpreter across 13 mathematical, symbolic, and algorithmic reasoning tasks from BIG-Bench Hard and other benchmarks. In all these natural language reasoning tasks, generating code using an LLM and reasoning using a Python interpreter leads to more accurate results than much larger models. For example, PAL using Codex achieves state-of-the-art few-shot accuracy on the GSM8K benchmark of math word problems, surpassing PaLM-540B which uses chain-of-thought by absolute 15% top-1. Our code and data are publicly available at http://reasonwithpal.com/ .",
      "standard_url": "http://arxiv.org/abs/2211.10435v2",
      "id": "2022-pal:_program-aided_language_models"
    },
    "11": {
      "enum": "11",
      "authors": "Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, Jiawei Zhang",
      "title": "Chat-rec: Towards interactive and explainable llms-augmented recommender system",
      "publication": "arXiv preprint arXiv:2303.14524",
      "year": 2023,
      "summary": "Large language models (LLMs) have demonstrated their significant potential to be applied for addressing various application tasks. However, traditional recommender systems continue to face great challenges such as poor interactivity and explainability, which actually also hinder their broad deployment in real-world systems. To address these limitations, this paper proposes a novel paradigm called Chat-Rec (ChatGPT Augmented Recommender System) that innovatively augments LLMs for building conversational recommender systems by converting user profiles and historical interactions into prompts. Chat-Rec is demonstrated to be effective in learning user preferences and establishing connections between users and products through in-context learning, which also makes the recommendation process more interactive and explainable. What's more, within the Chat-Rec framework, user's preferences can transfer to different products for cross-domain recommendations, and prompt-based injection of information into LLMs can also handle the cold-start scenarios with new items. In our experiments, Chat-Rec effectively improve the results of top-k recommendations and performs better in zero-shot rating prediction task. Chat-Rec offers a novel approach to improving recommender systems and presents new practical scenarios for the implementation of AIGC (AI generated content) in recommender system studies.",
      "standard_url": "http://arxiv.org/abs/2303.14524v2",
      "id": "2023-chat-rec:_towards_interactive_and_explainable_llms-augmented_recommender_system"
    },
    "12": {
      "enum": "12",
      "authors": "Wang-Cheng Kang, Julian McAuley",
      "title": "Self-attentive sequential recommendation",
      "publication": "In 2018 IEEE international conference on data mining (ICDM), 197‚Äì206. IEEE",
      "year": 2018,
      "summary": "Sequential dynamics are a key feature of many modern recommender systems, which seek to capture the `context' of users' activities on the basis of actions they have performed recently. To capture such patterns, two approaches have proliferated: Markov Chains (MCs) and Recurrent Neural Networks (RNNs). Markov Chains assume that a user's next action can be predicted on the basis of just their last (or last few) actions, while RNNs in principle allow for longer-term semantics to be uncovered. Generally speaking, MC-based methods perform best in extremely sparse datasets, where model parsimony is critical, while RNNs perform better in denser datasets where higher model complexity is affordable. The goal of our work is to balance these two goals, by proposing a self-attention based sequential model (SASRec) that allows us to capture long-term semantics (like an RNN), but, using an attention mechanism, makes its predictions based on relatively few actions (like an MC). At each time step, SASRec seeks to identify which items are `relevant' from a user's action history, and use them to predict the next item. Extensive empirical studies show that our method outperforms various state-of-the-art sequential models (including MC/CNN/RNN-based approaches) on both sparse and dense datasets. Moreover, the model is an order of magnitude more efficient than comparable CNN/RNN-based models. Visualizations on attention weights also show how our model adaptively handles datasets with various density, and uncovers meaningful patterns in activity sequences.",
      "standard_url": "http://arxiv.org/abs/1808.09781v1",
      "id": "2018-self-attentive_sequential_recommendation"
    },
    "13": {
      "enum": "13",
      "authors": "Wang-Cheng Kang, Jianmo Ni, Nikhil Mehta, Maheswaran Sathiamoorthy, Lichan Hong, Ed Chi, Derek Zhiyuan Cheng",
      "title": "Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction",
      "publication": "arXiv preprint arXiv:2305.06474",
      "year": 2023,
      "summary": "Large Language Models (LLMs) have demonstrated exceptional capabilities in generalizing to new tasks in a zero-shot or few-shot manner. However, the extent to which LLMs can comprehend user preferences based on their previous behavior remains an emerging and still unclear research question. Traditionally, Collaborative Filtering (CF) has been the most effective method for these tasks, predominantly relying on the extensive volume of rating data. In contrast, LLMs typically demand considerably less data while maintaining an exhaustive world knowledge about each item, such as movies or products. In this paper, we conduct a thorough examination of both CF and LLMs within the classic task of user rating prediction, which involves predicting a user's rating for a candidate item based on their past ratings. We investigate various LLMs in different sizes, ranging from 250M to 540B parameters and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We conduct comprehensive analysis to compare between LLMs and strong CF methods, and find that zero-shot LLMs lag behind traditional recommender models that have the access to user interaction data, indicating the importance of user interaction data. However, through fine-tuning, LLMs achieve comparable or even better performance with only a small fraction of the training data, demonstrating their potential through data efficiency.",
      "standard_url": "http://arxiv.org/abs/2305.06474v1",
      "id": "2023-do_llms_understand_user_preferences?_evaluating_llms_on_user_rating_prediction"
    },
    "14": {
      "enum": "14",
      "authors": "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa",
      "title": "Large language models are zero-shot reasoners",
      "publication": "Advances in neural information processing systems, 35: 22199‚Äì22213",
      "year": 2022,
      "summary": "Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding \"Let's think step by step\" before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with large InstructGPT model (text-davinci-002), as well as similar magnitudes of improvements with another off-the-shelf large model, 540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.",
      "standard_url": "http://arxiv.org/abs/2205.11916v4",
      "id": "2022-large_language_models_are_zero-shot_reasoners"
    },
    "15": {
      "enum": "15",
      "authors": "Raymond Li, Samira Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, Chris Pal",
      "title": "Towards deep conversational recommendations",
      "publication": "Advances in neural information processing systems, 31",
      "year": 2018,
      "summary": "There has been growing interest in using neural networks and deep learning techniques to create dialogue systems. Conversational recommendation is an interesting setting for the scientific exploration of dialogue with natural language as the associated discourse involves goal-driven dialogue that often transforms naturally into more free-form chat. This paper provides two contributions. First, until now there has been no publicly available large-scale dataset consisting of real-world dialogues centered around recommendations. To address this issue and to facilitate our exploration here, we have collected ReDial, a dataset consisting of over 10,000 conversations centered around the theme of providing movie recommendations. We make this data available to the community for further research. Second, we use this dataset to explore multiple facets of conversational recommendations. In particular we explore new neural architectures, mechanisms, and methods suitable for composing conversational recommendation systems. Our dataset allows us to systematically probe model sub-components addressing different parts of the overall problem domain ranging from: sentiment analysis and cold-start recommendation generation to detailed aspects of how natural language is used in this setting in the real world. We combine such sub-components into a full-blown dialogue system and examine its behavior.",
      "standard_url": "http://arxiv.org/abs/1812.07617v2",
      "id": "2018-towards_deep_conversational_recommendations"
    },
    "16": {
      "enum": "16",
      "authors": "Linden, G.; Smith, B.; and York, J. 2003",
      "title": "Amazon. com recommendations: Item-to-item collaborative filtering",
      "publication": "IEEE Internet computing, 7(1): 76‚Äì80",
      "year": null,
      "summary": null,
      "standard_url": null,
      "id": "None-amazon._com_recommendations:_item-to-item_collaborative_filtering"
    },
    "17": {
      "enum": "17",
      "authors": "Junling Liu, Chao Liu, Peilin Zhou, Renjie Lv, Kang Zhou, Yan Zhang",
      "title": "Is chatgpt a good recommender? a preliminary study",
      "publication": "arXiv preprint arXiv:2304.10149",
      "year": 2023,
      "summary": "Recommendation systems have witnessed significant advancements and have been widely used over the past decades. However, most traditional recommendation methods are task-specific and therefore lack efficient generalization ability. Recently, the emergence of ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of conversational models. Nonetheless, the application of ChatGPT in the recommendation domain has not been thoroughly investigated. In this paper, we employ ChatGPT as a general-purpose recommendation model to explore its potential for transferring extensive linguistic and world knowledge acquired from large-scale corpora to recommendation scenarios. Specifically, we design a set of prompts and evaluate ChatGPT's performance on five recommendation scenarios. Unlike traditional recommendation methods, we do not fine-tune ChatGPT during the entire evaluation process, relying only on the prompts themselves to convert recommendation tasks into natural language tasks. Further, we explore the use of few-shot prompting to inject interaction information that contains user potential interest to help ChatGPT better understand user needs and interests. Comprehensive experimental results on Amazon Beauty dataset show that ChatGPT has achieved promising results in certain tasks and is capable of reaching the baseline level in others. We conduct human evaluations on two explainability-oriented tasks to more accurately evaluate the quality of contents generated by different models. And the human evaluations show ChatGPT can truly understand the provided information and generate clearer and more reasonable results. We hope that our study can inspire researchers to further explore the potential of language models like ChatGPT to improve recommendation performance and contribute to the advancement of the recommendation systems field.",
      "standard_url": "http://arxiv.org/abs/2304.10149v3",
      "id": "2023-is_chatgpt_a_good_recommender?_a_preliminary_study"
    },
    "18": {
      "enum": "18",
      "authors": "Liu, J.; Shen, D.; Zhang, Y.; Dolan, B.; Carin, L.; and Chen, W. 2021",
      "title": "What Makes Good In-Context Examples for GPT-3333?",
      "publication": "arXiv preprint arXiv:2101.06804",
      "year": "2101",
      "summary": null,
      "standard_url": null,
      "id": "2101-what_makes_good_in-context_examples_for_gpt-3333?"
    },
    "19": {
      "enum": "19",
      "authors": "Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, Guannan Zhang",
      "title": "Think-in-memory: Recalling and post-thinking enable llms with long-term memory",
      "publication": "arXiv preprint arXiv:2311.08719",
      "year": 2023,
      "summary": "Memory-augmented Large Language Models (LLMs) have demonstrated remarkable performance in long-term human-machine interactions, which basically relies on iterative recalling and reasoning of history to generate high-quality responses. However, such repeated recall-reason steps easily produce biased thoughts, \\textit{i.e.}, inconsistent reasoning results when recalling the same history for different questions. On the contrary, humans can keep thoughts in the memory and recall them without repeated reasoning. Motivated by this human capability, we propose a novel memory mechanism called TiM (Think-in-Memory) that enables LLMs to maintain an evolved memory for storing historical thoughts along the conversation stream. The TiM framework consists of two crucial stages: (1) before generating a response, a LLM agent recalls relevant thoughts from memory, and (2) after generating a response, the LLM agent post-thinks and incorporates both historical and new thoughts to update the memory. Thus, TiM can eliminate the issue of repeated reasoning by saving the post-thinking thoughts as the history. Besides, we formulate the basic principles to organize the thoughts in memory based on the well-established operations, (\\textit{i.e.}, insert, forget, and merge operations), allowing for dynamic updates and evolution of the thoughts. Furthermore, we introduce Locality-Sensitive Hashing into TiM to achieve efficient retrieval for the long-term conversations. We conduct qualitative and quantitative experiments on real-world and simulated dialogues covering a wide range of topics, demonstrating that equipping existing LLMs with TiM significantly enhances their performance in generating responses for long-term interactions.",
      "standard_url": "http://arxiv.org/abs/2311.08719v1",
      "id": "2023-think-in-memory:_recalling_and_post-thinking_enable_llms_with_long-term_memory"
    },
    "20": {
      "enum": "20",
      "authors": "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, Peter Clark",
      "title": "Self-refine: Iterative refinement with self-feedback",
      "publication": "arXiv preprint arXiv:2303.17651",
      "year": 2023,
      "summary": "Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",
      "standard_url": "http://arxiv.org/abs/2303.17651v2",
      "id": "2023-self-refine:_iterative_refinement_with_self-feedback"
    },
    "21": {
      "enum": "21",
      "authors": "Mirzadeh, N.; Ricci, F.; and Bansal, M. 2005",
      "title": "Feature selection methods for conversational recommender systems",
      "publication": "In 2005 IEEE International Conference on e-Technology, e-Commerce and e-Service, 772‚Äì777. IEEE",
      "year": null,
      "summary": null,
      "standard_url": null,
      "id": "None-feature_selection_methods_for_conversational_recommender_systems"
    },
    "22": {
      "enum": "22",
      "authors": "Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, John Schulman",
      "title": "Webgpt: Browser-assisted question-answering with human feedback",
      "publication": "arXiv preprint arXiv:2112.09332",
      "year": 2021,
      "summary": "We fine-tune GPT-3 to answer long-form questions using a text-based web-browsing environment, which allows the model to search and navigate the web. By setting up the task so that it can be performed by humans, we are able to train models on the task using imitation learning, and then optimize answer quality with human feedback. To make human evaluation of factual accuracy easier, models must collect references while browsing in support of their answers. We train and evaluate our models on ELI5, a dataset of questions asked by Reddit users. Our best model is obtained by fine-tuning GPT-3 using behavior cloning, and then performing rejection sampling against a reward model trained to predict human preferences. This model's answers are preferred by humans 56% of the time to those of our human demonstrators, and 69% of the time to the highest-voted answer from Reddit.",
      "standard_url": "http://arxiv.org/abs/2112.09332v3",
      "id": "2021-webgpt:_browser-assisted_question-answering_with_human_feedback"
    },
    "23": {
      "enum": "23",
      "authors": "OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Sim√≥n Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, ≈Åukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, ≈Åukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David M√©ly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O'Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cer√≥n Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, Barret Zoph",
      "title": "GPT-4 Technical Report",
      "publication": "arXiv:2303.08774",
      "year": 2023,
      "summary": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
      "standard_url": "http://arxiv.org/abs/2303.08774v6",
      "id": "2023-gpt-4_technical_report"
    },
    "24": {
      "enum": "24",
      "authors": "Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe",
      "title": "Training language models to follow instructions with human feedback",
      "publication": "Advances in Neural Information Processing Systems, 35: 27730‚Äì27744",
      "year": 2022,
      "summary": "Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.",
      "standard_url": "http://arxiv.org/abs/2203.02155v1",
      "id": "2022-training_language_models_to_follow_instructions_with_human_feedback"
    },
    "25": {
      "enum": "25",
      "authors": "Gustavo Penha, Claudia Hauff",
      "title": "What does bert know about books, movies and music? probing bert for conversational recommendation",
      "publication": "In Proceedings of the 14th ACM Conference on Recommender Systems, 388‚Äì397",
      "year": 2020,
      "summary": "Heavily pre-trained transformer models such as BERT have recently shown to be remarkably powerful at language modelling by achieving impressive results on numerous downstream tasks. It has also been shown that they are able to implicitly store factual knowledge in their parameters after pre-training. Understanding what the pre-training procedure of LMs actually learns is a crucial step for using and improving them for Conversational Recommender Systems (CRS). We first study how much off-the-shelf pre-trained BERT \"knows\" about recommendation items such as books, movies and music. In order to analyze the knowledge stored in BERT's parameters, we use different probes that require different types of knowledge to solve, namely content-based and collaborative-based. Content-based knowledge is knowledge that requires the model to match the titles of items with their content information, such as textual descriptions and genres. In contrast, collaborative-based knowledge requires the model to match items with similar ones, according to community interactions such as ratings. We resort to BERT's Masked Language Modelling head to probe its knowledge about the genre of items, with cloze style prompts. In addition, we employ BERT's Next Sentence Prediction head and representations' similarity to compare relevant and non-relevant search and recommendation query-document inputs to explore whether BERT can, without any fine-tuning, rank relevant items first. Finally, we study how BERT performs in a conversational recommendation downstream task. Overall, our analyses and experiments show that: (i) BERT has knowledge stored in its parameters about the content of books, movies and music; (ii) it has more content-based knowledge than collaborative-based knowledge; and (iii) fails on conversational recommendation when faced with adversarial data.",
      "standard_url": "http://arxiv.org/abs/2007.15356v2",
      "id": "2020-what_does_bert_know_about_books_movies_and_music?_probing_bert_for_conversational_recommendation"
    },
    "26": {
      "enum": "26",
      "authors": "Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, Maosong Sun",
      "title": "Tool learning with foundation models",
      "publication": "arXiv preprint arXiv:2304.08354",
      "year": 2023,
      "summary": "Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of foundation models, AI systems have the potential to be equally adept in tool use as humans. This paradigm, i.e., tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research into tool-augmented and tool-oriented learning. We formulate a general tool learning framework: starting from understanding the user instruction, models should learn to decompose a complex task into several subtasks, dynamically adjust their plan through reasoning, and effectively conquer each sub-task by selecting appropriate tools. We also discuss how to train models for improved tool-use capabilities and facilitate the generalization in tool learning. Considering the lack of a systematic tool learning evaluation in prior works, we experiment with 18 representative tools and show the potential of current foundation models in skillfully utilizing tools. Finally, we discuss several open problems that require further investigation for tool learning. In general, we hope this paper could inspire future research in integrating tools with foundation models.",
      "standard_url": "http://arxiv.org/abs/2304.08354v3",
      "id": "2023-tool_learning_with_foundation_models"
    },
    "27": {
      "enum": "27",
      "authors": "Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, Maosong Sun",
      "title": "Toolllm: Facilitating large language models to master 16000+ real-world apis",
      "publication": "arXiv preprint arXiv:2307.16789",
      "year": 2023,
      "summary": "Despite the advancements of open-source large language models (LLMs), e.g., LLaMA, they remain significantly limited in tool-use capabilities, i.e., using external tools (APIs) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM, a general tool-use framework encompassing data construction, model training, and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is constructed automatically using ChatGPT. Specifically, the construction can be divided into three stages: (i) API collection: we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to generate diverse instructions involving these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To enhance the reasoning capabilities of LLMs, we develop a novel depth-first search-based decision tree algorithm. It enables LLMs to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it with a neural API retriever to recommend appropriate APIs for each instruction. Experiments show that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: APIBench.",
      "standard_url": "http://arxiv.org/abs/2307.16789v2",
      "id": "2023-toolllm:_facilitating_large_language_models_to_master_16000+_real-world_apis"
    },
    "28": {
      "enum": "28",
      "authors": "Ohad Rubin, Jonathan Herzig, Jonathan Berant",
      "title": "Learning to retrieve prompts for in-context learning",
      "publication": "arXiv preprint arXiv:2112.08633",
      "year": 2021,
      "summary": "In-context learning is a recent paradigm in natural language understanding, where a large pre-trained language model (LM) observes a test instance and a few training examples as its input, and directly decodes the output without any update to its parameters. However, performance has been shown to strongly depend on the selected training examples (termed prompt). In this work, we propose an efficient method for retrieving prompts for in-context learning using annotated data and a LM. Given an input-output pair, we estimate the probability of the output given the input and a candidate training example as the prompt, and label training examples as positive or negative based on this probability. We then train an efficient dense retriever from this data, which is used to retrieve training examples as prompts at test time. We evaluate our approach on three sequence-to-sequence tasks where language utterances are mapped to meaning representations, and find that it substantially outperforms prior work and multiple baselines across the board.",
      "standard_url": "http://arxiv.org/abs/2112.08633v2",
      "id": "2021-learning_to_retrieve_prompts_for_in-context_learning"
    },
    "29": {
      "enum": "29",
      "authors": "Timo Schick, Jane Dwivedi-Yu, Roberto Dess√¨, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom",
      "title": "Toolformer: Language models can teach themselves to use tools",
      "publication": "arXiv preprint arXiv:2302.04761",
      "year": 2023,
      "summary": "Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q\\&A system, two different search engines, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.",
      "standard_url": "http://arxiv.org/abs/2302.04761v1",
      "id": "2023-toolformer:_language_models_can_teach_themselves_to_use_tools"
    },
    "30": {
      "enum": "30",
      "authors": "Shen, Y.; Song, K.; Tan, X.; Li, D.; Lu, W.; and Zhuang, Y. 2023",
      "title": "Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface",
      "publication": "arXiv preprint arXiv:2303.17580",
      "year": "2303",
      "summary": null,
      "standard_url": null,
      "id": "2303-hugginggpt:_solving_ai_tasks_with_chatgpt_and_its_friends_in_huggingface"
    },
    "31": {
      "enum": "31",
      "authors": "Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao",
      "title": "Reflexion: Language agents with verbal reinforcement learning",
      "publication": "arXiv preprint arXiv:2303.11366",
      "year": 2023,
      "summary": "Large language models (LLMs) have been increasingly used to interact with external environments (e.g., games, compilers, APIs) as goal-driven agents. However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning. We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback. Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials. Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning). For example, Reflexion achieves a 91% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous state-of-the-art GPT-4 that achieves 80%. We also conduct ablation and analysis studies using different feedback signals, feedback incorporation methods, and agent types, and provide insights into how they affect performance.",
      "standard_url": "http://arxiv.org/abs/2303.11366v4",
      "id": "2023-reflexion:_language_agents_with_verbal_reinforcement_learning"
    },
    "32": {
      "enum": "32",
      "authors": "Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, Morteza Behrooz, William Ngan, Spencer Poff, Naman Goyal, Arthur Szlam, Y-Lan Boureau, Melanie Kambadur, Jason Weston",
      "title": "Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage",
      "publication": "arXiv preprint arXiv:2208.03188",
      "year": 2022,
      "summary": "We present BlenderBot 3, a 175B parameter dialogue model capable of open-domain conversation with access to the internet and a long-term memory, and having been trained on a large number of user defined tasks. We release both the model weights and code, and have also deployed the model on a public web page to interact with organic users. This technical report describes how the model was built (architecture, model and training scheme), and details of its deployment, including safety mechanisms. Human evaluations show its superiority to existing open-domain dialogue agents, including its predecessors (Roller et al., 2021; Komeili et al., 2022). Finally, we detail our plan for continual learning using the data collected from deployment, which will also be publicly released. The goal of this research program is thus to enable the community to study ever-improving responsible agents that learn through interaction.",
      "standard_url": "http://arxiv.org/abs/2208.03188v3",
      "id": "2022-blenderbot_3:_a_deployed_conversational_agent_that_continually_learns_to_responsibly_engage"
    },
    "33": {
      "enum": "33",
      "authors": "Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, Quoc Le",
      "title": "Lamda: Language models for dialog applications",
      "publication": "arXiv preprint arXiv:2201.08239",
      "year": 2022,
      "summary": "We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformer-based neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency.",
      "standard_url": "http://arxiv.org/abs/2201.08239v3",
      "id": "2022-lamda:_language_models_for_dialog_applications"
    },
    "34": {
      "enum": "34",
      "authors": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample",
      "title": "Llama: Open and efficient foundation language models",
      "publication": "arXiv preprint arXiv:2302.13971",
      "year": 2023,
      "summary": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.",
      "standard_url": "http://arxiv.org/abs/2302.13971v1",
      "id": "2023-llama:_open_and_efficient_foundation_language_models"
    },
    "35": {
      "enum": "35",
      "authors": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom",
      "title": "Llama 2: Open foundation and fine-tuned chat models",
      "publication": "arXiv preprint arXiv:2307.09288",
      "year": 2023,
      "summary": "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.",
      "standard_url": "http://arxiv.org/abs/2307.09288v2",
      "id": "2023-llama_2:_open_foundation_and_fine-tuned_chat_models"
    },
    "36": {
      "enum": "36",
      "authors": "Lingzhi Wang, Huang Hu, Lei Sha, Can Xu, Kam-Fai Wong, Daxin Jiang",
      "title": "Recindial: A unified framework for conversational recommendation with pretrained language models",
      "publication": "arXiv preprint arXiv:2110.07477",
      "year": 2021,
      "summary": "Conversational Recommender System (CRS), which aims to recommend high-quality items to users through interactive conversations, has gained great research interest recently. A CRS is usually composed of a recommendation module and a generation module. In the previous work, these two modules are loosely connected in the model training and are shallowly integrated during inference, where a simple switching or copy mechanism is adopted to incorporate recommended items into generated responses. Moreover, the current end-to-end neural models trained on small crowd-sourcing datasets (e.g., 10K dialogs in the ReDial dataset) tend to overfit and have poor chit-chat ability. In this work, we propose a novel unified framework that integrates recommendation into the dialog (RecInDial) generation by introducing a vocabulary pointer. To tackle the low-resource issue in CRS, we finetune the large-scale pretrained language models to generate fluent and diverse responses, and introduce a knowledge-aware bias learned from an entity-oriented knowledge graph to enhance the recommendation performance. Furthermore, we propose to evaluate the CRS models in an end-to-end manner, which can reflect the overall performance of the entire system rather than the performance of individual modules, compared to the separate evaluations of the two modules used in previous work. Experiments on the benchmark dataset ReDial show our RecInDial model significantly surpasses the state-of-the-art methods. More extensive analyses show the effectiveness of our model.",
      "standard_url": "http://arxiv.org/abs/2110.07477v2",
      "id": "2021-recindial:_a_unified_framework_for_conversational_recommendation_with_pretrained_language_models"
    },
    "37": {
      "enum": "37",
      "authors": "Lei Wang, Ee-Peng Lim",
      "title": "Zero-Shot Next-Item Recommendation using Large Pretrained Language Models",
      "publication": "arXiv preprint arXiv:2304.03153",
      "year": 2023,
      "summary": "Large language models (LLMs) have achieved impressive zero-shot performance in various natural language processing (NLP) tasks, demonstrating their capabilities for inference without training examples. Despite their success, no research has yet explored the potential of LLMs to perform next-item recommendations in the zero-shot setting. We have identified two major challenges that must be addressed to enable LLMs to act effectively as recommenders. First, the recommendation space can be extremely large for LLMs, and LLMs do not know about the target user's past interacted items and preferences. To address this gap, we propose a prompting strategy called Zero-Shot Next-Item Recommendation (NIR) prompting that directs LLMs to make next-item recommendations. Specifically, the NIR-based strategy involves using an external module to generate candidate items based on user-filtering or item-filtering. Our strategy incorporates a 3-step prompting that guides GPT-3 to carry subtasks that capture the user's preferences, select representative previously watched movies, and recommend a ranked list of 10 movies. We evaluate the proposed approach using GPT-3 on MovieLens 100K dataset and show that it achieves strong zero-shot performance, even outperforming some strong sequential recommendation models trained on the entire training dataset. These promising results highlight the ample research opportunities to use LLMs as recommenders. The code can be found at https://github.com/AGI-Edgerunners/LLM-Next-Item-Rec.",
      "standard_url": "http://arxiv.org/abs/2304.03153v1",
      "id": "2023-zero-shot_next-item_recommendation_using_large_pretrained_language_models"
    },
    "38": {
      "enum": "38",
      "authors": "Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, Ji-Rong Wen",
      "title": "A survey on large language model based autonomous agents",
      "publication": "arXiv preprint arXiv:2308.11432",
      "year": 2023,
      "summary": "Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.",
      "standard_url": "http://arxiv.org/abs/2308.11432v7",
      "id": "2023-a_survey_on_large_language_model_based_autonomous_agents"
    },
    "39": {
      "enum": "39",
      "authors": "Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-Peng Lim",
      "title": "Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models",
      "publication": "arXiv preprint arXiv:2305.04091",
      "year": 2023,
      "summary": "Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort, Zero-shot-CoT concatenates the target problem statement with \"Let's think step by step\" as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting. We evaluate our proposed prompting strategy on ten datasets across three reasoning problems. The experimental results over GPT-3 show that our proposed zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets by a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought Prompting, and has comparable performance with 8-shot CoT prompting on the math reasoning problem. The code can be found at https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.",
      "standard_url": "http://arxiv.org/abs/2305.04091v3",
      "id": "2023-plan-and-solve_prompting:_improving_zero-shot_chain-of-thought_reasoning_by_large_language_models"
    },
    "40": {
      "enum": "40",
      "authors": "Ting-Chun Wang, Shang-Yu Su, Yun-Nung Chen",
      "title": "BARCOR: Towards A Unified Framework for Conversational Recommendation Systems",
      "publication": "arXiv preprint arXiv:2203.14257",
      "year": 2022,
      "summary": "Recommendation systems focus on helping users find items of interest in the situations of information overload, where users' preferences are typically estimated by the past observed behaviors. In contrast, conversational recommendation systems (CRS) aim to understand users' preferences via interactions in conversation flows. CRS is a complex problem that consists of two main tasks: (1) recommendation and (2) response generation. Previous work often tried to solve the problem in a modular manner, where recommenders and response generators are separate neural models. Such modular architectures often come with a complicated and unintuitive connection between the modules, leading to inefficient learning and other issues. In this work, we propose a unified framework based on BART for conversational recommendation, which tackles two tasks in a single model. Furthermore, we also design and collect a lightweight knowledge graph for CRS in the movie domain. The experimental results show that the proposed methods achieve the state-of-the-art performance in terms of both automatic and human evaluation.",
      "standard_url": "http://arxiv.org/abs/2203.14257v1",
      "id": "2022-barcor:_towards_a_unified_framework_for_conversational_recommendation_systems"
    },
    "41": {
      "enum": "41",
      "authors": "Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, Furu Wei",
      "title": "Augmenting Language Models with Long-Term Memory",
      "publication": "arXiv preprint arXiv:2306.07174",
      "year": 2023,
      "summary": "Existing large language models (LLMs) can only afford fix-sized inputs due to the input length limit, preventing them from utilizing rich long-context information from past inputs. To address this, we propose a framework, Language Models Augmented with Long-Term Memory (LongMem), which enables LLMs to memorize long history. We design a novel decoupled network architecture with the original backbone LLM frozen as a memory encoder and an adaptive residual side-network as a memory retriever and reader. Such a decoupled memory design can easily cache and update long-term past contexts for memory retrieval without suffering from memory staleness. Enhanced with memory-augmented adaptation training, LongMem can thus memorize long past context and use long-term memory for language modeling. The proposed memory retrieval module can handle unlimited-length context in its memory bank to benefit various downstream tasks. Typically, LongMem can enlarge the long-form memory to 65k tokens and thus cache many-shot extra demonstration examples as long-form memory for in-context learning. Experiments show that our method outperforms strong long-context models on ChapterBreak, a challenging long-context modeling benchmark, and achieves remarkable improvements on memory-augmented in-context learning over LLMs. The results demonstrate that the proposed method is effective in helping language models to memorize and utilize long-form contents. Our code is open-sourced at https://aka.ms/LongMem.",
      "standard_url": "http://arxiv.org/abs/2306.07174v1",
      "id": "2023-augmenting_language_models_with_long-term_memory"
    },
    "42": {
      "enum": "42",
      "authors": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou",
      "title": "Self-consistency improves chain of thought reasoning in language models",
      "publication": "arXiv preprint arXiv:2203.11171",
      "year": 2022,
      "summary": "Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%).",
      "standard_url": "http://arxiv.org/abs/2203.11171v4",
      "id": "2022-self-consistency_improves_chain_of_thought_reasoning_in_language_models"
    },
    "43": {
      "enum": "43",
      "authors": "Xiaolei Wang, Kun Zhou, Ji-Rong Wen, Wayne Xin Zhao",
      "title": "Towards unified conversational recommender systems via knowledge-enhanced prompt learning",
      "publication": "In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 1929‚Äì1937",
      "year": 2022,
      "summary": "Conversational recommender systems (CRS) aim to proactively elicit user preference and recommend high-quality items through natural language conversations. Typically, a CRS consists of a recommendation module to predict preferred items for users and a conversation module to generate appropriate responses. To develop an effective CRS, it is essential to seamlessly integrate the two modules. Existing works either design semantic alignment strategies, or share knowledge resources and representations between the two modules. However, these approaches still rely on different architectures or techniques to develop the two modules, making it difficult for effective module integration.\n  To address this problem, we propose a unified CRS model named UniCRS based on knowledge-enhanced prompt learning. Our approach unifies the recommendation and conversation subtasks into the prompt learning paradigm, and utilizes knowledge-enhanced prompts based on a fixed pre-trained language model (PLM) to fulfill both subtasks in a unified approach. In the prompt design, we include fused knowledge representations, task-specific soft tokens, and the dialogue context, which can provide sufficient contextual information to adapt the PLM for the CRS task. Besides, for the recommendation subtask, we also incorporate the generated response template as an important part of the prompt, to enhance the information interaction between the two subtasks. Extensive experiments on two public CRS datasets have demonstrated the effectiveness of our approach.",
      "standard_url": "http://arxiv.org/abs/2206.09363v1",
      "id": "2022-towards_unified_conversational_recommender_systems_via_knowledge-enhanced_prompt_learning"
    },
    "44": {
      "enum": "44",
      "authors": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "publication": "Advances in Neural Information Processing Systems, 35: 24824‚Äì24837",
      "year": 2022,
      "summary": "We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.",
      "standard_url": "http://arxiv.org/abs/2201.11903v6",
      "id": "2022-chain-of-thought_prompting_elicits_reasoning_in_large_language_models"
    },
    "45": {
      "enum": "45",
      "authors": "Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, Nan Duan",
      "title": "Visual chatgpt: Talking, drawing and editing with visual foundation models",
      "publication": "arXiv preprint arXiv:2303.04671",
      "year": 2023,
      "summary": "ChatGPT is attracting a cross-field interest as it provides a language interface with remarkable conversational competency and reasoning capabilities across many domains. However, since ChatGPT is trained with languages, it is currently not capable of processing or generating images from the visual world. At the same time, Visual Foundation Models, such as Visual Transformers or Stable Diffusion, although showing great visual understanding and generation capabilities, they are only experts on specific tasks with one-round fixed inputs and outputs. To this end, We build a system called \\textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps. 3) providing feedback and asking for corrected results. We design a series of prompts to inject the visual model information into ChatGPT, considering models of multiple inputs/outputs and models that require visual feedback. Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models. Our system is publicly available at \\url{https://github.com/microsoft/visual-chatgpt}.",
      "standard_url": "http://arxiv.org/abs/2303.04671v1",
      "id": "2023-visual_chatgpt:_talking_drawing_and_editing_with_visual_foundation_models"
    },
    "46": {
      "enum": "46",
      "authors": "Zhihui Xie, Tong Yu, Canzhe Zhao, Shuai Li",
      "title": "Comparison-based conversational recommender system with relative bandit feedback",
      "publication": "In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, 1400‚Äì1409",
      "year": 2022,
      "summary": "With the recent advances of conversational recommendations, the recommender system is able to actively and dynamically elicit user preference via conversational interactions. To achieve this, the system periodically queries users' preference on attributes and collects their feedback. However, most existing conversational recommender systems only enable the user to provide absolute feedback to the attributes. In practice, the absolute feedback is usually limited, as the users tend to provide biased feedback when expressing the preference. Instead, the user is often more inclined to express comparative preferences, since user preferences are inherently relative. To enable users to provide comparative preferences during conversational interactions, we propose a novel comparison-based conversational recommender system. The relative feedback, though more practical, is not easy to be incorporated since its feedback scale is always mismatched with users' absolute preferences. With effectively collecting and understanding the relative feedback from an interactive manner, we further propose a new bandit algorithm, which we call RelativeConUCB. The experiments on both synthetic and real-world datasets validate the advantage of our proposed method, compared to the existing bandit algorithms in the conversational recommender systems.",
      "standard_url": "http://arxiv.org/abs/2208.09837v1",
      "id": "2022-comparison-based_conversational_recommender_system_with_relative_bandit_feedback"
    },
    "47": {
      "enum": "47",
      "authors": "Xu, K.; Yang, J.; Xu, J.; Gao, S.; Guo, J.; and Wen, J.-R. 2021",
      "title": "Adapting user preference to online feedback in multi-round conversational recommendation",
      "publication": "In Proceedings of the 14th ACM international conference on web search and data mining, 364‚Äì372",
      "year": null,
      "summary": null,
      "standard_url": null,
      "id": "None-adapting_user_preference_to_online_feedback_in_multi-round_conversational_recommendation"
    },
    "48": {
      "enum": "48",
      "authors": "Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, Lijuan Wang",
      "title": "Mm-react: Prompting chatgpt for multimodal reasoning and action",
      "publication": "arXiv preprint arXiv:2303.11381",
      "year": 2023,
      "summary": "We propose MM-REACT, a system paradigm that integrates ChatGPT with a pool of vision experts to achieve multimodal reasoning and action. In this paper, we define and explore a comprehensive list of advanced vision tasks that are intriguing to solve, but may exceed the capabilities of existing vision and vision-language models. To achieve such advanced visual intelligence, MM-REACT introduces a textual prompt design that can represent text descriptions, textualized spatial coordinates, and aligned file names for dense visual signals such as images and videos. MM-REACT's prompt design allows language models to accept, associate, and process multimodal information, thereby facilitating the synergetic combination of ChatGPT and various vision experts. Zero-shot experiments demonstrate MM-REACT's effectiveness in addressing the specified capabilities of interests and its wide application in different scenarios that require advanced visual understanding. Furthermore, we discuss and compare MM-REACT's system paradigm with an alternative approach that extends language models for multimodal scenarios through joint finetuning. Code, demo, video, and visualization are available at https://multimodal-react.github.io/",
      "standard_url": "http://arxiv.org/abs/2303.11381v1",
      "id": "2023-mm-react:_prompting_chatgpt_for_multimodal_reasoning_and_action"
    },
    "49": {
      "enum": "49",
      "authors": "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan",
      "title": "Tree of thoughts: Deliberate problem solving with large language models",
      "publication": "arXiv preprint arXiv:2305.10601",
      "year": 2023,
      "summary": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.",
      "standard_url": "http://arxiv.org/abs/2305.10601v2",
      "id": "2023-tree_of_thoughts:_deliberate_problem_solving_with_large_language_models"
    },
    "50": {
      "enum": "50",
      "authors": "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao",
      "title": "React: Synergizing reasoning and acting in language models",
      "publication": "arXiv preprint arXiv:2210.03629",
      "year": 2022,
      "summary": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io",
      "standard_url": "http://arxiv.org/abs/2210.03629v3",
      "id": "2022-react:_synergizing_reasoning_and_acting_in_language_models"
    },
    "51": {
      "enum": "51",
      "authors": "Zhang, Y.; Chen, X.; Ai, Q.; Yang, L.; and Croft, W. B. 2018",
      "title": "Towards conversational search and recommendation: System ask, user respond",
      "publication": "In Proceedings of the 27th acm international conference on information and knowledge management, 177‚Äì186",
      "year": null,
      "summary": null,
      "standard_url": null,
      "id": "None-towards_conversational_search_and_recommendation:_system_ask_user_respond"
    },
    "52": {
      "enum": "52",
      "authors": "Pengyu Zhao, Zijian Jin, Ning Cheng",
      "title": "An in-depth survey of large language model-based artificial intelligence agents",
      "publication": "arXiv preprint arXiv:2309.14365",
      "year": 2023,
      "summary": "Due to the powerful capabilities demonstrated by large language model (LLM), there has been a recent surge in efforts to integrate them with AI agents to enhance their performance. In this paper, we have explored the core differences and characteristics between LLM-based AI agents and traditional AI agents. Specifically, we first compare the fundamental characteristics of these two types of agents, clarifying the significant advantages of LLM-based agents in handling natural language, knowledge storage, and reasoning capabilities. Subsequently, we conducted an in-depth analysis of the key components of AI agents, including planning, memory, and tool use. Particularly, for the crucial component of memory, this paper introduced an innovative classification scheme, not only departing from traditional classification methods but also providing a fresh perspective on the design of an AI agent's memory system. We firmly believe that in-depth research and understanding of these core components will lay a solid foundation for the future advancement of AI agent technology. At the end of the paper, we provide directional suggestions for further research in this field, with the hope of offering valuable insights to scholars and researchers in the field.",
      "standard_url": "http://arxiv.org/abs/2309.14365v1",
      "id": "2023-an_in-depth_survey_of_large_language_model-based_artificial_intelligence_agents"
    },
    "53": {
      "enum": "53",
      "authors": "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica",
      "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena",
      "publication": "arXiv:2306.05685",
      "year": 2023,
      "summary": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
      "standard_url": "http://arxiv.org/abs/2306.05685v4",
      "id": "2023-judging_llm-as-a-judge_with_mt-bench_and_chatbot_arena"
    },
    "54": {
      "enum": "54",
      "authors": "Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang",
      "title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
      "publication": "arXiv preprint arXiv:2305.10250",
      "year": 2023,
      "summary": "Revolutionary advancements in Large Language Models have drastically reshaped our interactions with artificial intelligence systems. Despite this, a notable hindrance remains-the deficiency of a long-term memory mechanism within these models. This shortfall becomes increasingly evident in situations demanding sustained interaction, such as personal companion systems and psychological counseling. Therefore, we propose MemoryBank, a novel memory mechanism tailored for LLMs. MemoryBank enables the models to summon relevant memories, continually evolve through continuous memory updates, comprehend, and adapt to a user personality by synthesizing information from past interactions. To mimic anthropomorphic behaviors and selectively preserve memory, MemoryBank incorporates a memory updating mechanism, inspired by the Ebbinghaus Forgetting Curve theory, which permits the AI to forget and reinforce memory based on time elapsed and the relative significance of the memory, thereby offering a human-like memory mechanism. MemoryBank is versatile in accommodating both closed-source models like ChatGPT and open-source models like ChatGLM. We exemplify application of MemoryBank through the creation of an LLM-based chatbot named SiliconFriend in a long-term AI Companion scenario. Further tuned with psychological dialogs, SiliconFriend displays heightened empathy in its interactions. Experiment involves both qualitative analysis with real-world user dialogs and quantitative analysis with simulated dialogs. In the latter, ChatGPT acts as users with diverse characteristics and generates long-term dialog contexts covering a wide array of topics. The results of our analysis reveal that SiliconFriend, equipped with MemoryBank, exhibits a strong capability for long-term companionship as it can provide emphatic response, recall relevant memories and understand user personality.",
      "standard_url": "http://arxiv.org/abs/2305.10250v3",
      "id": "2023-memorybank:_enhancing_large_language_models_with_long-term_memory"
    },
    "55": {
      "enum": "55",
      "authors": "Jie Zou, Yifan Chen, Evangelos Kanoulas",
      "title": "Towards question-based recommender systems",
      "publication": "In Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval, 881‚Äì890",
      "year": 2020,
      "summary": "Conversational and question-based recommender systems have gained increasing attention in recent years, with users enabled to converse with the system and better control recommendations. Nevertheless, research in the field is still limited, compared to traditional recommender systems. In this work, we propose a novel Question-based recommendation method, Qrec, to assist users to find items interactively, by answering automatically constructed and algorithmically chosen questions. Previous conversational recommender systems ask users to express their preferences over items or item facets. Our model, instead, asks users to express their preferences over descriptive item features. The model is first trained offline by a novel matrix factorization algorithm, and then iteratively updates the user and item latent factors online by a closed-form solution based on the user answers. Meanwhile, our model infers the underlying user belief and preferences over items to learn an optimal question-asking strategy by using Generalized Binary Search, so as to ask a sequence of questions to the user. Our experimental results demonstrate that our proposed matrix factorization model outperforms the traditional Probabilistic Matrix Factorization model. Further, our proposed Qrec model can greatly improve the performance of state-of-the-art baselines, and it is also effective in the case of cold-start user and item recommendations.",
      "standard_url": "http://arxiv.org/abs/2005.14255v1",
      "id": "2020-towards_question-based_recommender_systems"
    },
    "56": {
      "enum": "56",
      "authors": "Jie Zou, Evangelos Kanoulas",
      "title": "Learning to ask: Question-based sequential Bayesian product search",
      "publication": "In Proceedings of the 28th ACM international conference on information and knowledge management, 369‚Äì378",
      "year": 2019,
      "summary": "Product search is generally recognized as the first and foremost stage of online shopping and thus significant for users and retailers of e-commerce. Most of the traditional retrieval methods use some similarity functions to match the user's query and the document that describes a product, either directly or in a latent vector space. However, user queries are often too general to capture the minute details of the specific product that a user is looking for. In this paper, we propose a novel interactive method to effectively locate the best matching product. The method is based on the assumption that there is a set of candidate questions for each product to be asked. In this work, we instantiate this candidate set by making the hypothesis that products can be discriminated by the entities that appear in the documents associated with them. We propose a Question-based Sequential Bayesian Product Search method, QSBPS, which directly queries users on the expected presence of entities in the relevant product documents. The method learns the product relevance as well as the reward of the potential questions to be asked to the user by being trained on the search history and purchase behavior of a specific user together with that of other users. The experimental results show that the proposed method can greatly improve the performance of product search compared to the state-of-the-art baselines.",
      "standard_url": "http://arxiv.org/abs/1908.11733v1",
      "id": "2019-learning_to_ask:_question-based_sequential_bayesian_product_search"
    }
  },
  "authors": "Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, Xing Xie",
  "summary": "Recommender models excel at providing domain-specific item recommendations by leveraging extensive user behavior data. Despite their ability to act as lightweight domain experts, they struggle to perform versatile tasks such as providing explanations and engaging in conversations. On the other hand, large language models (LLMs) represent a significant step towards artificial general intelligence, showcasing remarkable capabilities in instruction comprehension, commonsense reasoning, and human interaction. However, LLMs lack the knowledge of domain-specific item catalogs and behavioral patterns, particularly in areas that diverge from general world knowledge, such as online e-commerce. Finetuning LLMs for each domain is neither economic nor efficient.\n  In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create a versatile and interactive recommender system. We introduce an efficient framework called \\textbf{InteRecAgent}, which employs LLMs as the brain and recommender models as tools. We first outline a minimal set of essential tools required to transform LLMs into InteRecAgent. We then propose an efficient workflow within InteRecAgent for task execution, incorporating key components such as memory components, dynamic demonstration-augmented task planning, and reflection. InteRecAgent enables traditional recommender systems, such as those ID-based matrix factorization models, to become interactive systems with a natural language interface through the integration of LLMs. Experimental results on several public datasets show that InteRecAgent achieves satisfying performance as a conversational recommender system, outperforming general-purpose LLMs. The source code of InteRecAgent is released at https://aka.ms/recagent.",
  "standard_url": "http://arxiv.org/abs/2308.16505v3",
  "id": "2023-recommender_ai_agent:_integrating_large_language_models_for_interactive_recommendations"
}